{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63142022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import tempfile\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "import numpy as np\n",
    "import visdom\n",
    "import scipy\n",
    "import einops\n",
    "import json\n",
    "from geomloss import SamplesLoss\n",
    "from torch import nn, optim\n",
    "from collections import defaultdict\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from math import sqrt\n",
    "from functools import partial, lru_cache\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Parameter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f55e20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset defined by my self\n",
    "class WarriorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_names = os.listdir(folder_path)\n",
    "        if transform:\n",
    "            self.transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((70, 70)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0, 0, 0), (1, 1, 1))\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        image_path = os.path.join(self.folder_path, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "    \n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5697bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.getcwd() + \"/Pictures/Warrior\"\n",
    "dataset = WarriorDataset(folder_path, transform=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "shuffle=True, batch_size=16, drop_last=True)\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "print(dataset[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d849ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'width': 32,\n",
    "    'dataset': 'easy_worrior',\n",
    "    'n_channels': 3,\n",
    "    'n_classes': 10,\n",
    "    'batch_size': 16,\n",
    "    'vid_batch': 16,\n",
    "    'latent_dim': 8,  # lower is better modelling but worst interpolation freedom\n",
    "    'lr': 0.005,\n",
    "    'log_every': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50cf8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['dataset'] == 'easy_worrior': # Test case\n",
    "    xb = next(train_iterator)\n",
    "    xb = xb.to(device)\n",
    "else:\n",
    "    xb,cb = next(train_iterator)\n",
    "    xb,cb = xb.to(device), cb.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6ebb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, n_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(512, 4, stride=1, padding=0),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU())  # 4x4\n",
    "        self.f2 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(256, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU())  # 8x8\n",
    "        self.f3 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(128, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU())  # 16x16\n",
    "        self.f4 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(n_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid())  # 32x32\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.f1(z)\n",
    "        x = self.f2(x)\n",
    "        x = self.f3(x)\n",
    "        x = self.f4(x)\n",
    "        # x = torch.nn.functional.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Decoder(args['latent_dim'], args['n_channels']).to(device)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=args['lr'])\n",
    "ot_loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "178c810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ot_loss(x, y):\n",
    "    return ot_loss_fn(x.view(x.size(0), -1), y.view(y.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c687cd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input samples 'x' and 'y' should have the same last dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m p_z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m g \u001b[38;5;241m=\u001b[39m net(p_z)\n\u001b[1;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mot_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ((g-xb)**2).mean()\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     15\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m, in \u001b[0;36mot_loss\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mot_loss\u001b[39m(x, y):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mot_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\geomloss\\samples_loss.py:217\u001b[0m, in \u001b[0;36mSamplesLoss.forward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m\"\"\"Computes the loss between sampled measures.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03mDocumentation and examples: Soon!\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03mUntil then, please check the tutorials :-)\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m l_x, α, x, l_y, β, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m--> 217\u001b[0m B, N, M, D, l_x, α, l_y, β \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mα\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mβ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m backend \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\n\u001b[0;32m    221\u001b[0m )  \u001b[38;5;66;03m# Choose the backend -----------------------------------------\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m l_y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\geomloss\\samples_loss.py:347\u001b[0m, in \u001b[0;36mSamplesLoss.check_shapes\u001b[1;34m(self, l_x, α, x, l_y, β, y)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput samples \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should have the same number of dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput samples \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should have the same last dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m     )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    352\u001b[0m     x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    353\u001b[0m ):  \u001b[38;5;66;03m# No batch --------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Batchsize\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Input samples 'x' and 'y' should have the same last dimension."
     ]
    }
   ],
   "source": [
    "logs = {}\n",
    "logs['loss1'] = logs['loss2'] = logs['loss3'] = 0\n",
    "logs['num_stats'] = 0\n",
    "\n",
    "opt.zero_grad()\n",
    "\n",
    "# p(x | z)\n",
    "# p(x | z, p)\n",
    "\n",
    "p_z = torch.randn(args['batch_size'], args['latent_dim'], 1, 1).to(device)\n",
    "g = net(p_z)\n",
    "\n",
    "loss = ot_loss(g, xb)  # ((g-xb)**2).mean()\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1a7f1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.size(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e68921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ce672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e472976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
