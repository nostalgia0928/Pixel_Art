{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63142022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import tempfile\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "import numpy as np\n",
    "import visdom\n",
    "import scipy\n",
    "import einops\n",
    "import json\n",
    "from geomloss import SamplesLoss\n",
    "from torch import nn, optim\n",
    "from collections import defaultdict\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from math import sqrt\n",
    "from functools import partial, lru_cache\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Parameter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55e20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset defined by my self\n",
    "class WarriorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_names = os.listdir(folder_path)\n",
    "        if transform:\n",
    "            self.transform = torchvision.transforms.Compose([\n",
    "                #torchvision.transforms.Resize((70, 70)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                #torchvision.transforms.Normalize((0, 0, 0), (1, 1, 1))\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        image_path = os.path.join(self.folder_path, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "    \n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5697bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.getcwd() + \"/Pictures/Warrior\"\n",
    "dataset = WarriorDataset(folder_path, transform=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "shuffle=True, batch_size=16, drop_last=True)\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "print(dataset[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d849ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'width': 32,\n",
    "    'dataset': 'easy_warrior',\n",
    "    'n_channels': 3,\n",
    "    'n_classes': 10,\n",
    "    'batch_size': 16,\n",
    "    'vid_batch': 16,\n",
    "    'latent_dim': 8,  # lower is better modelling but worst interpolation freedom\n",
    "    'lr': 0.005,\n",
    "    'log_every': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cf8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['dataset'] == 'easy_warrior': # Test case\n",
    "    xb = next(train_iterator)\n",
    "    xb = xb.to(device)\n",
    "else:\n",
    "    xb,cb = next(train_iterator)\n",
    "    xb,cb = xb.to(device), cb.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6ebb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, n_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(512, 4, stride=1, padding=0),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),  # Output: [512, 4, 4]\n",
    "\n",
    "            nn.LazyConvTranspose2d(256, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),  # Output: [256, 8, 8]\n",
    "\n",
    "            nn.LazyConvTranspose2d(128, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),  # Output: [128, 16, 16]\n",
    "\n",
    "            nn.LazyConvTranspose2d(64, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),  # Output: [64, 32, 32]\n",
    "\n",
    "            nn.LazyConvTranspose2d(32, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),  # Output: [32, 64, 64]\n",
    "\n",
    "            nn.LazyConvTranspose2d(n_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid()  # Output: [3, 128, 128]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.decoder(z)\n",
    "        # Crop from [3, 128, 128] to [3, 69, 44]\n",
    "        x = x[:, :, :44, :69]\n",
    "\n",
    "        # change n_channels above to match number of colours\n",
    "\n",
    "        # 0,0,0,0,1,0,0,0,0,\n",
    "        # softmax(0.3, -0.2, 1.5, ...) -> 0.001, 0.0000, 0.9, 0.00\n",
    "\n",
    "        # # when implementing the softmax, you'll need to remove the sigmoid then do:\n",
    "        # may need to view x to make this work\n",
    "        # x = torch.softmax(x, dim=1)\n",
    "\n",
    "        # to test your softmax code is working, do\n",
    "        # x.sum(dim=1) , check this is all 1's\n",
    "        # inspect say x[0, :, 30, 22] # make sure it looks like a PMF\n",
    "\n",
    "        # Change n_channels above to match the number of colors\n",
    "\n",
    "        # Apply softmax to convert the output to a probability distribution\n",
    "#         x = x.contiguous().view(x.size(0), -1)  # Reshape x to [batch_size, num_features]\n",
    "        print(x.size())\n",
    "#         x = torch.softmax(x, dim=1)\n",
    "#         print(x.sum(dim=1))\n",
    "#         x = x.view(x.size(0), args['n_channels'], 69, 44)  # Reshape back to [batch_size, n_channels, 69, 44]\n",
    "#         # Test the softmax code\n",
    "#         print(x.sum(dim=(1,2,3)))  # Check that the sum is 1 for each channel\n",
    "#         print(x[0, :, 30, 22])  # Inspect the probability mass function (PMF) for a specific pixel\n",
    "        return x\n",
    "\n",
    "net = Decoder(args['latent_dim'], args['n_channels']).to(device)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=args['lr'])\n",
    "ot_loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178c810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ot_loss(x, y):\n",
    "    return ot_loss_fn(x.contiguous().view(x.size(0), -1), y.view(y.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c687cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 44, 69])\n"
     ]
    }
   ],
   "source": [
    "logs = {}\n",
    "logs['loss1'] = logs['loss2'] = logs['loss3'] = 0\n",
    "logs['num_stats'] = 0\n",
    "\n",
    "opt.zero_grad()\n",
    "\n",
    "# p(x | z)\n",
    "# p(x | z, p)\n",
    "\n",
    "p_z = torch.randn(args['batch_size'], args['latent_dim'], 1, 1).to(device)\n",
    "g = net(p_z)\n",
    "\n",
    "loss = ot_loss(g, xb)  # ((g-xb)**2).mean()\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a7f1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 44, 69])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51ce672",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43df177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique colors: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 17])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_colors(rgb_image):\n",
    "    reshaped_image = rgb_image.view(rgb_image.shape[0], -1)\n",
    "    unique_colors = torch.unique(reshaped_image, dim=1)\n",
    "    num_colors = unique_colors.shape[1]\n",
    "    print(\"Number of unique colors:\", num_colors)\n",
    "    return unique_colors\n",
    "\n",
    "unique_colors = get_unique_colors(dataset[1])\n",
    "unique_colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d9e869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3373, 0.0431, 0.1569])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][:,30,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2faa8588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rgb_to_palette(rgb_tensor, unique_colors): #rgb_tensor: CHW\n",
    "    num_classes = unique_colors.shape[1]\n",
    "    onehot = torch.zeros(num_classes, rgb_tensor.shape[1], rgb_tensor.shape[2])\n",
    "    for i in range(num_classes):\n",
    "        for j in range(rgb_tensor.shape[1]):\n",
    "            for k in range(rgb_tensor.shape[2]):\n",
    "                if rgb_tensor[:, j, k].equal(unique_colors[:, i]):\n",
    "                    onehot[i, j, k] = 1\n",
    "                \n",
    "    return onehot\n",
    "\n",
    "palette_tensor = rgb_to_palette(dataset[0], unique_colors)\n",
    "\n",
    "palette_tensor[:, 30, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c733b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def palette_to_rgb(palette_tensor, unique_colors): #palette_tensor: CHW\n",
    "    num_classes = unique_colors.shape[1]\n",
    "    rgb_tensor = torch.zeros(3, palette_tensor.shape[1], palette_tensor.shape[2])\n",
    "    for i in range(num_classes):\n",
    "        for j in range(rgb_tensor.shape[1]):\n",
    "            for k in range(rgb_tensor.shape[2]):\n",
    "                if palette_tensor[i, j, k] == 1:\n",
    "                    rgb_tensor[: , j, k] += unique_colors[:, i] \n",
    "    \n",
    "    return rgb_tensor\n",
    "\n",
    "rgb_tensor = palette_to_rgb(palette_tensor, unique_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27be1909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0534, 0.0534, 0.0534, 0.0534, 0.1452, 0.0534, 0.0534, 0.0534, 0.0534,\n",
      "        0.0534, 0.0534, 0.0534, 0.0534, 0.0534, 0.0534, 0.0534, 0.0534])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def palette_to_softmax(palette_tensor): #palette_tensor CHW\n",
    "    channels = palette_tensor.shape[-3]\n",
    "    height = palette_tensor.shape[-2]\n",
    "    width = palette_tensor.shape[-1]\n",
    "    palette_tensor = palette_tensor.contiguous().view(palette_tensor.size(0), -1)\n",
    "    palette_tensor = torch.softmax(palette_tensor, dim=0)\n",
    "    #print(palette_tensor.sum(dim=0))\n",
    "    #palette_tensor = palette_tensor.view(palette_tensor.size(0), channels, height, width)  # Reshape back to [batch_size, n_channels, 69, 44]\n",
    "    palette_tensor = palette_tensor.view(channels, height, width)\n",
    "    \n",
    "    #Test the softmax code\n",
    "    #print(palette_tensor.sum(dim=(0)))  # Check that the sum is 1 for each channel\n",
    "    print(palette_tensor[:, 30, 22])\n",
    "    print(sum(palette_tensor[:, 30, 22]))  # Inspect the probability mass function (PMF) for a specific pixe\n",
    "    return palette_tensor\n",
    "\n",
    "softmax_tensor = palette_to_softmax(palette_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4d4ff7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_to_palette(softmax_tensor): #CHW\n",
    "    palette_tensor = torch.zeros(softmax_tensor.shape[-3], softmax_tensor.shape[-2], softmax_tensor.shape[-1])\n",
    "    for i in range(softmax_tensor.shape[-2]):\n",
    "        for j in range(softmax_tensor.shape[-1]):\n",
    "            index = torch.argmax(softmax_tensor[:, i, j])\n",
    "            palette_tensor[index, i, j] = 1\n",
    "    \n",
    "    return palette_tensor\n",
    "\n",
    "a = softmax_to_palette(softmax_tensor)\n",
    "a[:, 30 , 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04432ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 44, 69])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####For BCHW######\n",
    "xb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aec09c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "Number of unique colors: 20\n"
     ]
    }
   ],
   "source": [
    "def batch_get_unique_colors(rgb_image):   # BCHW\n",
    "    rgb_image = rgb_image.permute(1, 0, 2, 3)\n",
    "    reshaped_image = rgb_image.contiguous().view(rgb_image.shape[0], -1)\n",
    "    unique_colors = torch.unique(reshaped_image, dim=1)\n",
    "    print(unique_colors.size())\n",
    "    num_colors = unique_colors.shape[1]\n",
    "    print(\"Number of unique colors:\", num_colors)\n",
    "    return unique_colors\n",
    "\n",
    "unique_colors = batch_get_unique_colors(xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01b7a765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48576, 20])\n",
      "torch.Size([16, 20, 44, 69])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def batch_rgb_to_palette(rgb_tensor, unique_colors):\n",
    "    num_classes = unique_colors.shape[1]\n",
    "    \n",
    "    reshaped_tensor = rgb_tensor.permute(0, 2, 3, 1).contiguous().view(-1, rgb_tensor.shape[1])\n",
    "    unique_colors = unique_colors.t()\n",
    "    \n",
    "    onehot = (reshaped_tensor[:, None, :] == unique_colors[None, :, :]).all(dim=2) #None can add new dim\n",
    "    print(onehot.size())\n",
    "    onehot = onehot.view(rgb_tensor.shape[0], rgb_tensor.shape[2], rgb_tensor.shape[3], num_classes).permute(0, 3, 1, 2).float()\n",
    "    print(onehot.size())\n",
    "    \n",
    "    return onehot\n",
    "\n",
    "palette_tensor = batch_rgb_to_palette(xb, unique_colors)\n",
    "pixel_value = palette_tensor[0, :, 30, 22]\n",
    "print(pixel_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aecfb483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.3020, 0.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def batch_palette_to_rgb(palette_tensor, unique_colors):\n",
    "    num_classes = unique_colors.shape[1]\n",
    "    \n",
    "    reshaped_palette = palette_tensor.permute(0, 2, 3, 1).contiguous().view(-1, num_classes)\n",
    "    reshaped_unique_colors = unique_colors.t()\n",
    "    \n",
    "    rgb_tensor = torch.matmul(reshaped_palette, reshaped_unique_colors)\n",
    "    rgb_tensor = rgb_tensor.view(palette_tensor.shape[0], 3, palette_tensor.shape[2], palette_tensor.shape[3])\n",
    "    \n",
    "    return rgb_tensor\n",
    "\n",
    "rgb_tensor = batch_palette_to_rgb(palette_tensor, unique_colors)\n",
    "print(rgb_tensor[0, :, 20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8289cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48576, 20])\n",
      "torch.Size([16, 20, 44, 69])\n",
      "tensor([0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "        0.0460, 0.1252, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "        0.0460, 0.0460], device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def batch_palette_to_softmax(palette_tensor): #palette_tensor BCHW\n",
    "    channels = palette_tensor.shape[-3]\n",
    "    \n",
    "    reshaped_palette = palette_tensor.permute(0, 2, 3, 1).contiguous().view(-1, channels)\n",
    "    print(reshaped_palette.size())\n",
    "    reshaped_palette = torch.softmax(reshaped_palette, dim=1)\n",
    "    palette_tensor = reshaped_palette.view(palette_tensor.shape[0], palette_tensor.shape[2], palette_tensor.shape[3], channels).permute(0, 3, 1, 2)\n",
    "    print(palette_tensor.size())\n",
    "    #Test the softmax code\n",
    "    print(palette_tensor[0, :, 30, 22])\n",
    "    print(sum(palette_tensor[4, :, 30, 22]))  # Inspect the probability mass function (PMF) for a specific pixe\n",
    "    return palette_tensor\n",
    "\n",
    "softmax_tensor = batch_palette_to_softmax(palette_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "620baf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 44, 69])\n",
      "torch.Size([16, 20, 44, 69])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_softmax_to_palette(softmax_tensor): #BCHW\n",
    "    _, indices = torch.max(softmax_tensor, dim=1)\n",
    "    print(indices.size())\n",
    "    b, h, w = softmax_tensor.shape[0], softmax_tensor.shape[2], softmax_tensor.shape[3]\n",
    "    device = softmax_tensor.device  # Ensure both on GPU\n",
    "    palette_tensor = torch.zeros(b, softmax_tensor.shape[1], h, w, device=device)  \n",
    "    palette_tensor.scatter_(1, indices.unsqueeze(1), 1)  # indice -> (B, 1, H, W) scatter(dim, index ,src) ？？？\n",
    "    print(palette_tensor.size())\n",
    "    return palette_tensor\n",
    "\n",
    "palette_tensor = batch_softmax_to_palette(softmax_tensor)\n",
    "palette_tensor[0, :, 30, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83ddf7f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA_scatter__value)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m     palette_tensor\u001b[38;5;241m.\u001b[39mscatter_(\u001b[38;5;241m1\u001b[39m, indices\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m palette_tensor\n\u001b[1;32m----> 9\u001b[0m palette_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_softmax_to_palette\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoftmax_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m palette_tensor[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m22\u001b[39m]\n",
      "Cell \u001b[1;32mIn[80], line 5\u001b[0m, in \u001b[0;36mbatch_softmax_to_palette\u001b[1;34m(softmax_tensor)\u001b[0m\n\u001b[0;32m      3\u001b[0m b, h, w \u001b[38;5;241m=\u001b[39m softmax_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], softmax_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], softmax_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m      4\u001b[0m palette_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(b, softmax_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], h, w)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpalette_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m palette_tensor\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA_scatter__value)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f31d6d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd996347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
