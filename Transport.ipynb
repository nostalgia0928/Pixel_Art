{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fc8423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\http\\client.py\", line 1374, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\http\\client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\http\\client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=10080): Max retries exceeded with url: http://ncc1.clients.dur.ac.uk:8023/env/main (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\visdom\\__init__.py\", line 756, in _send\n",
      "    return self._handle_post(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\visdom\\__init__.py\", line 720, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 635, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 559, in send\n",
      "    raise ProxyError(e, request=request)\n",
      "requests.exceptions.ProxyError: HTTPConnectionPool(host='127.0.0.1', port=10080): Max retries exceeded with url: http://ncc1.clients.dur.ac.uk:8023/env/main (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
      "[Errno 11001] getaddrinfo failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\http\\client.py\", line 1374, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\http\\client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\http\\client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=10080): Max retries exceeded with url: http://ncc1.clients.dur.ac.uk:8023/events (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None)))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\visdom\\__init__.py\", line 756, in _send\n",
      "    return self._handle_post(\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\visdom\\__init__.py\", line 720, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 635, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\Nostalgia\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 559, in send\n",
      "    raise ProxyError(e, request=request)\n",
      "requests.exceptions.ProxyError: HTTPConnectionPool(host='127.0.0.1', port=10080): Max retries exceeded with url: http://ncc1.clients.dur.ac.uk:8023/events (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None)))\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n",
      "[Errno 11001] getaddrinfo failed\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import tempfile\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "import numpy as np\n",
    "import visdom\n",
    "import scipy\n",
    "import einops\n",
    "import json\n",
    "from geomloss import SamplesLoss\n",
    "from torch import nn, optim\n",
    "from collections import defaultdict\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from math import sqrt\n",
    "from functools import partial, lru_cache\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "vis = visdom.Visdom(server= 'http://ncc1.clients.dur.ac.uk', port=8023)\n",
    "\n",
    "txt = ''\n",
    "callback_text_window = vis.text(txt, win='quit', opts={'title': 'type here to stop training safely'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d230c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m             curr_txt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m         vis\u001b[38;5;241m.\u001b[39mtext(curr_txt, win\u001b[38;5;241m=\u001b[39mcallback_text_window)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mvis\u001b[49m\u001b[38;5;241m.\u001b[39mregister_event_handler(type_callback, callback_text_window)\n\u001b[0;32m     12\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_every\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     22\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vis' is not defined"
     ]
    }
   ],
   "source": [
    "def type_callback(event):\n",
    "    if event['event_type'] == 'KeyPress':\n",
    "        curr_txt = event['pane_data']['content']\n",
    "        if event['key'] == 'Delete':\n",
    "            curr_txt = txt\n",
    "        elif len(event['key']) == 1:\n",
    "            curr_txt += event['key']\n",
    "        vis.text(curr_txt, win=callback_text_window)\n",
    "\n",
    "vis.register_event_handler(type_callback, callback_text_window)\n",
    "\n",
    "args = {\n",
    "    'width': 32,\n",
    "    'dataset': 'mnist',\n",
    "    'n_channels': 3,\n",
    "    'n_classes': 10,\n",
    "    'batch_size': 16,\n",
    "    'vid_batch': 16,\n",
    "    'latent_dim': 8, # lower is better modelling but worst interpolation freedom \n",
    "    'lr' : 0.005,\n",
    "    'log_every': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e75c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(tensor, win=\"video\", opts=None, num_channels=1):\n",
    "    if num_channels == 1:\n",
    "        fmt = \"gray\"\n",
    "        b = (tensor*255).byte().numpy().tobytes()\n",
    "    else:\n",
    "        fmt = \"rgb24\"\n",
    "        b = tensor.permute(0,3,1,2).contiguous()\n",
    "        b = b.view(b.size(0), b.size(1)*b.size(2), b.size(3)).contiguous()\n",
    "        b = b.permute(0,2,1).contiguous()\n",
    "        b = (b*255).byte().numpy().tobytes()\n",
    "\n",
    "    videofile_fd = tempfile.NamedTemporaryFile(suffix='.mp4')\n",
    "    videofile = videofile_fd.name\n",
    "\n",
    "    subprocess.run(['/usr/bin/ffmpeg', '-s', '%dx%d' %\n",
    "                    (tensor.shape[3], tensor.shape[2]),\n",
    "                    '-f', 'rawvideo',\n",
    "                    '-pix_fmt', fmt,\n",
    "                    '-y', '-i', '-',\n",
    "                    '-vcodec', 'h264',\n",
    "                    '-pix_fmt', 'yuv420p',\n",
    "                    '-c:v', 'libx264',\n",
    "                    '-loglevel', 'panic',\n",
    "                    videofile], input=b)\n",
    "\n",
    "    return vis.video(videofile=videofile, win=win, opts=opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec88f39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maquarium_fish\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaby\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeaver\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbed\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbee\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeetle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicycle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbowl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbridge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbus\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbutterfly\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcastle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaterpillar\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcattle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchair\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchimpanzee\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclock\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcloud\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcockroach\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcouch\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrab\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrocodile\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcup\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdinosaur\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdolphin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melephant\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflatfish\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfox\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgirl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhamster\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouse\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkangaroo\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomputer_keyboard\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlawn_mower\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleopard\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlion\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlizard\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlobster\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mman\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaple_tree\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotorcycle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmountain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouse\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmushroom\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moak_tree\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morchid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124motter\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpalm_tree\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_truck\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpine_tree\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoppy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mporcupine\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpossum\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrabbit\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraccoon\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroad\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrocket\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrose\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msea\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshark\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshrew\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskunk\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyscraper\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnail\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnake\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspider\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquirrel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreetcar\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msunflower\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msweet_pepper\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtank\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtelephone\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtelevision\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiger\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtractor\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrout\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtulip\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mturtle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwardrobe\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhale\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwillow_tree\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwolf\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwoman\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworm\u001b[39m\u001b[38;5;124m'\u001b[39m,]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43margs\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar100\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      4\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m      5\u001b[0m         torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR100(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      6\u001b[0m             torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      7\u001b[0m             torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m         ])),\n\u001b[0;32m      9\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m     train_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(cycle(train_loader))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm',]\n",
    "\n",
    "if args['dataset'] == 'cifar100':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR100('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0,0,0), (1,1,1))\n",
    "        ])),\n",
    "    shuffle=True, batch_size=1, drop_last=True)\n",
    "    train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "if args['dataset'] == 'mnist':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(3),\n",
    "            torchvision.transforms.Resize(32),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Lambda(lambda x : 1-x)\n",
    "        ])),\n",
    "    shuffle=True, batch_size=args['batch_size'], drop_last=True)\n",
    "    class_names = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "    train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "if args['dataset'] == 'fashion':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.FashionMNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(3),\n",
    "            torchvision.transforms.Resize(32),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Lambda(lambda x : 1-x)\n",
    "        ])),\n",
    "    shuffle=True, batch_size=args['batch_size'], drop_last=True)\n",
    "    class_names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "    train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "if args['dataset'] == 'celeba':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CelebA('data', download=True, transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize([args['width'],args['width']]),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0,0,0), (1,1,1))\n",
    "        ])),\n",
    "    shuffle=True, batch_size=args['batch_size'], drop_last=True)\n",
    "    train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "if args['dataset'] == 'cifar':\n",
    "    train_loader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0,0,0), (1,1,1))\n",
    "    ])), \n",
    "    shuffle=True, batch_size=args['batch_size'], drop_last=True)\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "if args['dataset'] == 'churches':\n",
    "    train_loader = torch.utils.data.DataLoader(torchvision.datasets.LSUN(\n",
    "        \"/home2/projects/cgw/lsun\", classes=[\"church_outdoor_train\"], transform=torchvision.transforms.Compose([\n",
    "         torchvision.transforms.CenterCrop(args['width']),\n",
    "         torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "         torchvision.transforms.Resize(args['width']),\n",
    "         torchvision.transforms.ToTensor()])), \n",
    "    shuffle=True, batch_size=args['batch_size'], drop_last=True)\n",
    "    train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "if args['dataset'] == 'ffhq':\n",
    "    train_loader = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        \"/home2/projects/cgw/FFHQ-256\", transform=torchvision.transforms.Compose([\n",
    "         torchvision.transforms.Resize(args['width']),\n",
    "         torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "         torchvision.transforms.ToTensor()])), \n",
    "    shuffle=True, batch_size=args['batch_size'], drop_last=True)\n",
    "    train_iterator = iter(cycle(train_loader))\n",
    "\n",
    "if args['dataset'] == 'noise':\n",
    "    def inf_dataset(batch_size):\n",
    "        while True:\n",
    "            yield torch.rand(batch_size, 1, 32,32).to(device), torch.zeros(batch_size, 40).long()\n",
    "    train_iterator = iter(cycle(inf_dataset(args['batch_size'])))\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407058db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting visdom\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 9.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.8 in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (1.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (2.28.1)\n",
      "Requirement already satisfied: tornado in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (6.1)\n",
      "Requirement already satisfied: six in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (1.16.0)\n",
      "Collecting jsonpatch\n",
      "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (0.58.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (2.8.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from visdom) (9.4.0)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from requests->visdom) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from requests->visdom) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from requests->visdom) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nostalgia\\anaconda3\\lib\\site-packages (from requests->visdom) (3.4)\n",
      "Building wheels for collected packages: visdom\n",
      "  Building wheel for visdom (setup.py): started\n",
      "  Building wheel for visdom (setup.py): finished with status 'done'\n",
      "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408312 sha256=932b89fda66debdeb088a5c98286cf34d8ed1aaaba977045211245f1f01ef7dc\n",
      "  Stored in directory: c:\\users\\nostalgia\\appdata\\local\\pip\\cache\\wheels\\d7\\94\\e8\\9e718f98bc717d1e6530d59d46e23996cc60cf2a28f1937ed4\n",
      "Successfully built visdom\n",
      "Installing collected packages: jsonpointer, jsonpatch, visdom\n",
      "Successfully installed jsonpatch-1.32 jsonpointer-2.3 visdom-0.2.4\n"
     ]
    }
   ],
   "source": [
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "def ot_loss(x, y):\n",
    "    return ot_loss_fn(x.view(x.size(0),-1), y.view(y.size(0),-1))\n",
    "\n",
    "def lerp(a, b, t):\n",
    "    return (1-t)*a + t*b\n",
    "            \n",
    "def slerp(a, b, t):\n",
    "    omega = torch.acos((a/torch.norm(a, dim=1, keepdim=True)*b/torch.norm(b, dim=1, keepdim=True)).sum(1)).unsqueeze(1)\n",
    "    res = (torch.sin((1.0-t)*omega)/torch.sin(omega))*a + (torch.sin(t*omega)/torch.sin(omega)) * b\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1255a889",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDecoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, latent_dim, n_channels):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Decoder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, n_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(512, 4, stride=1, padding=0),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU()) # 4x4\n",
    "        self.f2 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(256, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU()) # 8x8\n",
    "        self.f3 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(128, 4, stride=2, padding=1),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU()) # 16x16\n",
    "        self.f4 = nn.Sequential(\n",
    "            nn.LazyConvTranspose2d(n_channels, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid()) # 32x32\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.f1(z)\n",
    "        x = self.f2(x)\n",
    "        x = self.f3(x)\n",
    "        x = self.f4(x)\n",
    "        # x = torch.nn.functional.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56afdab0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mDecoder\u001b[49m(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m'\u001b[39m], args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_channels\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m ot_loss_fn \u001b[38;5;241m=\u001b[39m SamplesLoss(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msinkhorn\u001b[39m\u001b[38;5;124m\"\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, blur\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Decoder' is not defined"
     ]
    }
   ],
   "source": [
    "net = Decoder(args['latent_dim'], args['n_channels']).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=args['lr'])\n",
    "ot_loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.001)\n",
    "\n",
    "epoch = 0\n",
    "start_time = time.time()\n",
    "global_step = 0\n",
    "\n",
    "vis.line(\n",
    "    X=[0],\n",
    "    Y=[[0, 0, 0]],\n",
    "    win='losses',\n",
    "    opts={'legend': ['loss1', 'loss2', 'loss3'], 'ytype': 'log'}\n",
    ")\n",
    "\n",
    "def sample_prior():\n",
    "    p_z = torch.randn(args['batch_size'], args['latent_dim'], 1, 1).to(device)\n",
    "    return p_z\n",
    "\n",
    "def cost(x, y):\n",
    "    return ((x-y)**2).sum(1).mean()\n",
    "\n",
    "# grabs a batch of data from the dataset\n",
    "xb,cb = next(train_iterator)\n",
    "xb,cb = xb.to(device), cb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "while (True):\n",
    "    \n",
    "    # # grabs a batch of data from the dataset\n",
    "    # xb,cb = next(train_iterator)\n",
    "    # xb,cb = xb.to(device), cb.to(device)\n",
    "\n",
    "    # arrays for metrics\n",
    "    logs = {}\n",
    "    logs['loss1'] = logs['loss2'] = logs['loss3'] = 0\n",
    "    logs['num_stats'] = 0\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # p(x | z)\n",
    "    # p(x | z, p)\n",
    "\n",
    "    p_z = torch.randn(args['batch_size'], args['latent_dim'], 1, 1).to(device)\n",
    "    g = net(p_z, palette_data)\n",
    "\n",
    "    loss = ot_loss(g, xb) # ((g-xb)**2).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # accumulate statistics\n",
    "    logs['loss1'] += loss.item()\n",
    "    logs['loss2'] += loss.item()\n",
    "    logs['loss3'] += loss.item()\n",
    "    logs['num_stats'] += 1\n",
    "\n",
    "    # update global step counter\n",
    "    global_step += 1\n",
    "\n",
    "    # log the loss value\n",
    "    if global_step % args['log_every'] == 0:\n",
    "        logs['loss1'] /= logs['num_stats']\n",
    "        logs['loss2'] /= logs['num_stats']\n",
    "        logs['loss3'] /= logs['num_stats']\n",
    "\n",
    "        vis.line(\n",
    "            X=[global_step],\n",
    "            Y=[[logs['loss1'], logs['loss2'], logs['loss3']]],\n",
    "            win='losses',\n",
    "            update='append'\n",
    "        )\n",
    "\n",
    "        logs['loss1'] = logs['loss2'] = logs['loss3'] = logs['num_stats'] = 0\n",
    "\n",
    "        print(f\"Memory: { (torch.cuda.max_memory_allocated()/1000000.0) } mb, step = {global_step + 1}: loss = {loss.item():.4f}\")\n",
    "    \n",
    "        # safely exit the loop\n",
    "        if len(json.loads(vis.get_window_data('quit'))['content']) > 0:\n",
    "            vis.text('', win='quit')\n",
    "            print(\"Exiting safely...\")\n",
    "            break\n",
    "\n",
    "    if (global_step) % 50 == 49:\n",
    "\n",
    "        vid_batch = args['vid_batch']\n",
    "        vis.image(torchvision.utils.make_grid(torch.clamp(g.data[:vid_batch], 0, 1), padding=0, nrow=int(np.sqrt(vid_batch))), win='p_xg0', opts={'title':'p_xg0 reconstructions', 'jpgquality':50})\n",
    "\n",
    "    if (global_step) % 100 == 99:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            vid_batch = args['vid_batch']\n",
    "\n",
    "            # Show latent interpolations SLERP video\n",
    "            z1 = sample_prior()[:vid_batch]\n",
    "            z2 = sample_prior()[:vid_batch]\n",
    "\n",
    "            frames = 64\n",
    "\n",
    "            ts = torch.linspace(0,1,frames)\n",
    "            vsx = args['width']*int(np.sqrt(vid_batch))\n",
    "            vid = torch.zeros(frames, 3, vsx, vsx)\n",
    "\n",
    "            for j in range(frames):\n",
    "                zs = lerp(z1, z2, ts[j])\n",
    "                with torch.no_grad():\n",
    "                    v = net(zs)\n",
    "\n",
    "                vid[j] = torchvision.utils.make_grid(torch.clamp(v,0,1), nrow=int(np.sqrt(vid_batch)), padding=0)\n",
    "\n",
    "            show_video(vid, num_channels=args['n_channels'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
